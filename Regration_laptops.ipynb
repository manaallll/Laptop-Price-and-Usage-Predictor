{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a regression model for laptop price dataset. The dataset consists of  feature, which are independent and charge as a dependent feature. We will predict laptops costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library and Dataset\n",
    "Now we will import couple of python library required for our analysis and import dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m----------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39mTraceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from io import StringIO\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "plt.rcParams['font.size'] =10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv('laptop_price.csv')\n",
    "print('\\nNumber of rows and columns in the data set: ',df.shape)\n",
    "print('')\n",
    "\n",
    "#Lets look into top few rows and columns in the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Shape\n",
    "print(\"Data Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Types\n",
    "print(\"\\nData Types:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. ScreenResolution processing\n",
    "    df['ScreenResolution'] = df['ScreenResolution'].astype(str).fillna('Unknown')\n",
    "    \n",
    "    # Extract resolution and screen type\n",
    "    resolution_split = df['ScreenResolution'].str.split(' ', expand=False)\n",
    "    df['Resolution'] = resolution_split.str[-1]\n",
    "    df['Screen'] = resolution_split.apply(lambda x: ' '.join(x[:-1]) if len(x) > 1 else 'Standard')\n",
    "    \n",
    "    # Extract width and height from resolution (e.g., \"1920x1080\")\n",
    "    resolution_parts = df['Resolution'].str.split('x', expand=True)\n",
    "    df['ScreenW'] = resolution_parts[0].replace('', '0').fillna('0').astype('float')\n",
    "    df['ScreenH'] = resolution_parts[1].replace('', '0').fillna('0').astype('float')   \n",
    "    # Screen features extraction\n",
    "    df['Touchscreen'] = df['Screen'].str.contains('Touchscreen').map({True: 'Yes', False: 'No'})\n",
    "    df['IPSpanel'] = df['Screen'].str.contains('IPS Panel').map({True: 'Yes', False: 'No'})\n",
    "    df['RetinaDisplay'] = df['Screen'].str.contains('Retina Display').map({True: 'Yes', False: 'No'})\n",
    "    \n",
    "    # Clean up screen description\n",
    "    df['Screen'] = df['Screen'].str.replace('Touchscreen|IPS Panel|Retina Display|/', '', regex=True)\n",
    "    df['Screen'] = df['Screen'].str.strip()\n",
    "    df['Screen'] = np.where(df['Screen'].str.len() > 0, df['Screen'], 'Standard')\n",
    "    df.drop(inplace=True, columns=['ScreenResolution'])\n",
    "\n",
    "    # 2. CPU processing - initialize with string dtype\n",
    "    df['CPU_brand'] = ''\n",
    "    df['CPU_model_and_generation'] = ''\n",
    "    df['CPU_base_clock_speed'] = ''\n",
    "    \n",
    "    for index, value in df['Cpu'].items():\n",
    "        if pd.isna(value):\n",
    "            continue\n",
    "            \n",
    "        parts = str(value).split()\n",
    "        if not parts:\n",
    "            continue\n",
    "            \n",
    "        # Brand (first word)\n",
    "        df.at[index, 'CPU_brand'] = parts[0]\n",
    "        \n",
    "        # Model and generation (middle words)\n",
    "        if len(parts) > 1:\n",
    "            model_parts = parts[1:-1] if len(parts) > 2 else [parts[1]]\n",
    "            df.at[index, 'CPU_model_and_generation'] = ' '.join(model_parts)\n",
    "        \n",
    "        # Clock speed (last word)\n",
    "        if len(parts) > 1:\n",
    "            df.at[index, 'CPU_base_clock_speed'] = parts[-1]\n",
    "\n",
    "\n",
    "    # 3. Memory/Storage processing\n",
    "    # Ensure Memory is string type and handle NaN values\n",
    "    df.drop(inplace=True, columns=['Cpu'])\n",
    "\n",
    "    df['Memory'] = df['Memory'].astype(str)\n",
    "    \n",
    "    # Split memory components\n",
    "    df['Memory'] = df['Memory'].str.split('+').apply(lambda x: [part.strip() for part in x])\n",
    "    \n",
    "    # Primary storage\n",
    "    df['PrimaryStorage'] = df['Memory'].apply(lambda x: x[0] if len(x) > 0 else '0')\n",
    "    df['PrimaryStorageType'] = df['PrimaryStorage'].str.extract(r'(\\D+)$')[0].str.strip()\n",
    "    df['PrimaryStorage'] = df['PrimaryStorage'].str.extract(r'^(\\d+)')[0].fillna(np.nan)\n",
    "    \n",
    "    # Secondary storage\n",
    "    df['SecondaryStorage'] = df['Memory'].apply(\n",
    "        lambda x: x[1] if len(x) > 1 else '0'\n",
    "    )\n",
    "    secondary_split = df['SecondaryStorage'].str.split(n=1, expand=True)\n",
    "    df['SecondaryStorageType'] = secondary_split[1].fillna('No')\n",
    "    df['SecondaryStorage'] = secondary_split[0].fillna('0')\n",
    "    df['PrimaryStorage'] = df['PrimaryStorage'].apply(convert_to_gb).astype('int64')\n",
    "    df['SecondaryStorage'] = df['SecondaryStorage'].apply(convert_to_gb).astype('int64')\n",
    "    df.drop(columns=['Memory'], inplace=True)\n",
    "\n",
    "    # 4. GPU processing\n",
    "    df['Gpu'] = df['Gpu'].astype(str)\n",
    "    gpu_split = df['Gpu'].str.split(n=1, expand=True)\n",
    "    df['GPU_company'] = gpu_split[0]\n",
    "    df['GPU_model'] = gpu_split[1].fillna('Unknown')\n",
    "    df.drop(columns=['Gpu'], inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_gb(value):\n",
    "    # Convert storage values to gigabytes.\n",
    "    if pd.isna(value):  # Handle NaN/None values\n",
    "        return 0.0\n",
    "        \n",
    "    value = str(value).strip().upper()  # Ensure string and standardize case\n",
    "    \n",
    "    try:\n",
    "        if 'TB' in value:\n",
    "            return float(value.replace('TB', '')) * 1024\n",
    "        elif 'GB' in value:\n",
    "            return float(value.replace('GB', ''))\n",
    "        elif 'MB' in value:  # Handle megabytes if needed\n",
    "            return float(value.replace('MB', '')) / 1024\n",
    "        else:  # Assume value is already in GB or a raw number\n",
    "            return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=preprocess(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSummary Statistics:\\n\", df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['laptop_ID','Resolution'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df[\"Weight\"] = df[\"Weight\"].str.replace(\"kg\",\"\").astype(float)\n",
    "    df[\"Ram\"] = df[\"Ram\"].str.replace(\"GB\", \"\").astype(float)\n",
    "    df[\"CPU_base_clock_speed\"] = df[\"CPU_base_clock_speed\"].str.replace(\"GHz\",\"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"processed_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Visualizing feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Price Distribution by Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x='Company', y='Price_euros', data=df)\n",
    "plt.title('Price Distribution by Company', fontsize=16)\n",
    "plt.xlabel('Company', fontsize=14)\n",
    "plt.ylabel('Price (Euros)', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Most Common Laptop Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "type_counts = df['TypeName'].value_counts()\n",
    "sns.barplot(x=type_counts.index, y=type_counts.values)\n",
    "plt.title('Most Common Laptop Types', fontsize=16)\n",
    "plt.xlabel('Type', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Price vs. Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Weight', y='Price_euros', hue='Company', data=df, alpha=0.7)\n",
    "plt.title('Price vs. Weight by Company', fontsize=16)\n",
    "plt.xlabel('Weight (kg)', fontsize=14)\n",
    "plt.ylabel('Price (Euros)', fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. RAM Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Ram', data=df, order=df['Ram'].value_counts().index)\n",
    "plt.title('RAM Distribution', fontsize=16)\n",
    "plt.xlabel('RAM (GB)', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Operating System Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "os_counts = df['OpSys'].value_counts()\n",
    "sns.barplot(x=os_counts.index, y=os_counts.values)\n",
    "plt.title('Operating System Distribution', fontsize=16)\n",
    "plt.xlabel('Operating System', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Screen Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Inches', data=df)\n",
    "plt.title('Screen Size Distribution', fontsize=16)\n",
    "plt.xlabel('Screen Size (Inches)', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. CPU Brand Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "cpu_counts = df['CPU_brand'].value_counts()\n",
    "sns.barplot(x=cpu_counts.index, y=cpu_counts.values)\n",
    "plt.title('CPU Brand Distribution', fontsize=16)\n",
    "plt.xlabel('CPU Brand', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. GPU Company Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "gpu_counts = df['GPU_company'].value_counts()\n",
    "sns.barplot(x=gpu_counts.index, y=gpu_counts.values)\n",
    "plt.title('GPU Company Distribution', fontsize=16)\n",
    "plt.xlabel('GPU Company', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Storage Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "primary_storage = df['PrimaryStorageType'].value_counts()\n",
    "secondary_storage = df['SecondaryStorageType'].value_counts()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=primary_storage.index, y=primary_storage.values)\n",
    "plt.title('Primary Storage Type', fontsize=14)\n",
    "plt.xlabel('Storage Type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=secondary_storage.index, y=secondary_storage.values)\n",
    "plt.title('Secondary Storage Type', fontsize=14)\n",
    "plt.xlabel('Storage Type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Correlation matrix Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns for correlation\n",
    "numerical_cols = ['Inches', 'Ram', 'Weight', 'Price_euros', 'ScreenW', 'ScreenH']\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = df[numerical_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Price Distribution by CPU Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='CPU_brand', y='Price_euros', data=df)\n",
    "plt.title('Price Distribution by CPU Brand', fontsize=16)\n",
    "plt.xlabel('CPU Brand', fontsize=14)\n",
    "plt.ylabel('Price (Euros)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Average Price by Company and Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "avg_price = df.groupby(['Company', 'TypeName'])['Price_euros'].mean().unstack()\n",
    "sns.heatmap(avg_price, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
    "plt.title('Average Price by Company and Type', fontsize=16)\n",
    "plt.xlabel('Type', fontsize=14)\n",
    "plt.ylabel('Company', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Touchscreen vs Non-Touchscreen Price Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Touchscreen', y='Price_euros', data=df)\n",
    "plt.title('Price Comparison: Touchscreen vs Non-Touchscreen', fontsize=16)\n",
    "plt.xlabel('Touchscreen', fontsize=14)\n",
    "plt.ylabel('Price (Euros)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Screen Resolution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for resolution\n",
    "df['Resolution'] = df['ScreenW'].astype(str) + 'x' + df['ScreenH'].astype(str)\n",
    "top_resolutions = df['Resolution'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_resolutions.index, y=top_resolutions.values)\n",
    "plt.title('Top 10 Screen Resolutions', fontsize=16)\n",
    "plt.xlabel('Resolution', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "Clean the data by addressing outliers and converting categorical features to numerical representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame\n",
    "# Apply quantile-based outlier removal\n",
    "\n",
    "for col in ['Price_euros','Ram','Weight', 'Inches']:\n",
    "    p_lower = 0.01  # 1st percentile\n",
    "    p_upper = 0.97  # 97th percentile\n",
    "    lower_bound = df[col].quantile(p_lower)\n",
    "    upper_bound = df[col].quantile(p_upper)\n",
    "    \n",
    "    # Clip values beyond the range\n",
    "    df[col] = np.clip(df[col], lower_bound, upper_bound)\n",
    "\n",
    "# Boxplots after outlier treatment\n",
    "modified_cols = ['Price_euros','Ram', 'Weight', 'Inches']\n",
    "for col in modified_cols:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(y=df[col])  # Show distribution after outlier removal\n",
    "    plt.title(f'Boxplot of {col} after outliers treatment', fontsize=16)\n",
    "    plt.xlabel(col, fontsize=14)\n",
    "    plt.ylabel(\"Value\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "droping columns that are too detailed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model=df.drop(columns=['Product','CPU_model_and_generation','GPU_model','Resolution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.to_csv(\"preprosseced.csv\",)\n",
    "print(df_model.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders={}\n",
    "for column in df_model.select_dtypes(include='object').columns:\n",
    "    le=LabelEncoder()\n",
    "    df_model[column]=le.fit_transform(df_model[column].astype(str))\n",
    "    label_encoders[column]=le\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.select_dtypes(include=np.number)\n",
    "\n",
    "correlation_matrix = numerical_cols.corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.to_csv(\"encoded_dataset.csv\")\n",
    "print(df_model.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop(columns=['Price_euros'])\n",
    "y = df_model['Price_euros']\n",
    "feature_columns = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size= 0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model1: random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def evaluate_regressors(X_train, X_test, y_train, y_test, X_cols):\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "        \"KNN Regressor\": KNeighborsRegressor(n_neighbors=5)\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        print(f\"R²:  {r2:.4f}\")\n",
    "        print(f\"MSE: {mse:.2f}\")\n",
    "        print(f\"MAE: {mae:.2f}\")\n",
    "\n",
    "        # Residual Plot\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        residuals = y_test - y_pred\n",
    "        sns.scatterplot(x=y_pred, y=residuals)\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        plt.title(f\"{name} - Residual Plot\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Residuals\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Predicted vs Actual\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.scatterplot(x=y_test, y=y_pred)\n",
    "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "        plt.title(f\"{name} - Predicted vs Actual\")\n",
    "        plt.xlabel(\"Actual\")\n",
    "        plt.ylabel(\"Predicted\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Feature Importance (Tree Models Only)\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "            names = [X_cols[i] for i in indices]\n",
    "\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.title(f\"{name} - Feature Importance\")\n",
    "            plt.bar(range(len(importances)), importances[indices])\n",
    "            plt.xticks(range(len(importances)), names, rotation=90)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Decision Tree Plot (Optional for Decision Tree only)\n",
    "        if name == \"Decision Tree\":\n",
    "            plt.figure(figsize=(16, 6))\n",
    "            plot_tree(model, feature_names=X_cols, filled=True, max_depth=3, fontsize=6)\n",
    "            plt.title(\"Decision Tree (max_depth=4)\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_regressors(X_train, X_test, y_train, y_test, X.columns.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
